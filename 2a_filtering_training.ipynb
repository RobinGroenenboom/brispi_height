{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52089d-c12c-4a32-841f-3992538ab77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Notebook\n",
    "\n",
    "# 1. Sampling Images\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def sample_images(source_folder, destination_folder, sample_size=20):\n",
    "    # Ensure the destination folder exists\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "    \n",
    "    # Get a list of all files in the source folder\n",
    "    all_files = os.listdir(source_folder)\n",
    "    \n",
    "    # Filter out non-image files (optional, based on common image extensions)\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'}\n",
    "    image_files = [f for f in all_files if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "    \n",
    "    # Check if the sample size is greater than the available images\n",
    "    if sample_size > len(image_files):\n",
    "        raise ValueError(f\"Sample size {sample_size} is greater than the number of available images {len(image_files)}.\")\n",
    "    \n",
    "    # Randomly select the sample size images\n",
    "    sampled_files = random.sample(image_files, sample_size)\n",
    "    \n",
    "    # Copy sampled files to the destination folder\n",
    "    for file in sampled_files:\n",
    "        src_path = os.path.join(source_folder, file)\n",
    "        dest_path = os.path.join(destination_folder, file)\n",
    "        shutil.copy(src_path, dest_path)\n",
    "    \n",
    "    print(f\"Sampled {sample_size} images to {destination_folder}\")\n",
    "\n",
    "# Specify the source and destination folders\n",
    "source_folder = 'filtered_images'\n",
    "destination_folder = 'sampled_images'\n",
    "\n",
    "# Sample 100 images\n",
    "sample_images(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281eedf-308d-42eb-889d-82bfd8786f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Plotting Sampled Images\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def plot_images(folder, images_per_plot=5):\n",
    "    # Get a list of all files in the folder\n",
    "    all_files = os.listdir(folder)\n",
    "    \n",
    "    # Filter out non-image files (optional, based on common image extensions)\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'}\n",
    "    image_files = [f for f in all_files if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "    \n",
    "    # Calculate the number of plots needed\n",
    "    num_plots = (len(image_files) + images_per_plot - 1) // images_per_plot\n",
    "    \n",
    "    # Plot the images\n",
    "    for i in range(num_plots):\n",
    "        fig, axs = plt.subplots(1, images_per_plot, figsize=(20, 5))\n",
    "        for j in range(images_per_plot):\n",
    "            idx = i * images_per_plot + j\n",
    "            if idx < len(image_files):\n",
    "                img_path = os.path.join(folder, image_files[idx])\n",
    "                img = Image.open(img_path)\n",
    "                axs[j].imshow(img)\n",
    "                axs[j].set_title(image_files[idx])\n",
    "                axs[j].axis('off')\n",
    "            else:\n",
    "                axs[j].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Specify the folder containing the sampled images\n",
    "folder = 'sampled_images'\n",
    "\n",
    "# Plot the images 5 at a time\n",
    "plot_images(folder, images_per_plot=5)\n",
    "\n",
    "# 3. Training the Filtering Model\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define directories\n",
    "mixed_img_dirs = ['yield_prediction_fennel/cnn_input_data_filtered', 'yield_prediction_fennel/sampled_images']\n",
    "good_img_dirs = ['yield_prediction_fennel/cnn_input_data_filtered2', 'yield_prediction_fennel/sampled_images2']\n",
    "\n",
    "# Create a label dictionary\n",
    "label_dict = {}\n",
    "# Label all images in the good_img_dirs as 1\n",
    "for good_img_dir in good_img_dirs:\n",
    "    for img in os.listdir(good_img_dir):\n",
    "        if img.lower().endswith('.jpg'):\n",
    "            label_dict[img] = 1\n",
    "# Label all images in the mixed_img_dirs as 0 if not already labeled as 1\n",
    "for mixed_img_dir in mixed_img_dirs:\n",
    "    for img in os.listdir(mixed_img_dir):\n",
    "        if img.lower().endswith('.jpg') and img not in label_dict:\n",
    "            label_dict[img] = 0\n",
    "\n",
    "# Verify the labels\n",
    "print(f\"Total labeled images: {len(label_dict)}\")\n",
    "print(f\"Number of good images: {sum(label_dict.values())}\")\n",
    "print(f\"Number of bad images: {len(label_dict) - sum(label_dict.values())}\")\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dirs, label_dict, transform=None):\n",
    "        self.img_dirs = img_dirs\n",
    "        self.label_dict = label_dict\n",
    "        self.transform = transform\n",
    "        self.img_labels = [(img, label_dict[img]) for img_dir in img_dirs for img in os.listdir(img_dir) if img in label_dict]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, label = self.img_labels[idx]\n",
    "        img_dir = [dir for dir in self.img_dirs if os.path.exists(os.path.join(dir, img_name))][0]\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations including data augmentation for the minority class\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "full_dataset = CustomImageDataset(mixed_img_dirs, label_dict, transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.1 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 2: Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "class_weights = torch.tensor([700/250, 1.0], dtype=torch.float)  # Adjust the weights based on the class imbalance\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68706e-d697-4172-8a72-334b13670e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the model\n",
    "num_epochs = 20\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 10 == 0:  # Print every 10 batches\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "    train_loss_list.append(running_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    val_loss_list.append(val_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {running_loss / len(train_loader):.4f}, Val Loss: {val_loss / len(val_loader):.4f}\")\n",
    "\n",
    "# Step 4: Evaluate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the model on the test images: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Plotting the loss\n",
    "plt.figure()\n",
    "plt.plot(train_loss_list, label='Train Loss')\n",
    "plt.plot(val_loss_list, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d6a76-f365-44bf-9d7f-6ff177fd4d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Testing the Filtering Model and Storing Metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming the model and dataset class are already defined as in the training script\n",
    "\n",
    "# Load and preprocess the data\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dirs, label_dict, transform=None):\n",
    "        self.img_dirs = img_dirs\n",
    "        self.label_dict = label_dict\n",
    "        self.transform = transform\n",
    "        self.img_labels = [(img, label_dict[img]) for img_dir in img_dirs for img in os.listdir(img_dir) if img in label_dict]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, label = self.img_labels[idx]\n",
    "        img_dir = [dir for dir in self.img_dirs if os.path.exists(os.path.join(dir, img_name))][0]\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "mixed_img_dirs = ['cnn_input_data_filtered', 'sampled_images']\n",
    "good_img_dirs = ['cnn_input_data_filtered2', 'sampled_images2']\n",
    "label_dict = {}\n",
    "for good_img_dir in good_img_dirs:\n",
    "    for img in os.listdir(good_img_dir):\n",
    "        if img.lower().endswith('.jpg'):\n",
    "            label_dict[img] = 1\n",
    "for mixed_img_dir in mixed_img_dirs:\n",
    "    for img in os.listdir(mixed_img_dir):\n",
    "        if img.lower().endswith('.jpg') and img not in label_dict:\n",
    "            label_dict[img] = 0\n",
    "\n",
    "full_dataset = CustomImageDataset(mixed_img_dirs, label_dict, transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.1 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the model (assuming SimpleCNN is defined as in the training script)\n",
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('filtering_model.pth'))  # Load the trained model\n",
    "model.eval()\n",
    "\n",
    "# Evaluate the model and store results\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_images = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_images.extend(images)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "class_report = classification_report(all_labels, all_preds, target_names=['Bad', 'Good'])\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot a few test images with their predicted and true labels\n",
    "num_images_to_plot = 20\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(num_images_to_plot):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    image = all_images[i].permute(1, 2, 0).numpy()\n",
    "    true_label = 'Good' if all_labels[i] == 1 else 'Bad'\n",
    "    predicted_label = 'Good' if all_preds[i] == 1 else 'Bad'\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'True: {true_label}\\nPred: {predicted_label}')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae6738-0e75-433b-b1f7-665b6dec72f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Manual Annotation and Additional Training\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider, Dropdown, Button, VBox, HBox, Label, Output\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define a custom dataset for the filtered images\n",
    "class FilteredImagesDataset(Dataset):\n",
    "    def __init__(self, img_names, img_dir, transform=None):\n",
    "        self.img_names = img_names\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Assign labels based on the filename (assuming this is how labels are determined)\n",
    "        if 'good' in img_name.lower():\n",
    "            label = 1  # Good\n",
    "        else:\n",
    "            label = 0  # Bad\n",
    "            \n",
    "        return image, img_name, label\n",
    "\n",
    "# Define the transform for the test dataset\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load image names from the directory, excluding those in the training directories\n",
    "test_img_dir = 'bright_spicy_2024/top_images' # now is split into good_top_images and bad_top_images\n",
    "training_dirs = ['yield_prediction_fennel/cnn_input_data_filtered', 'yield_prediction_fennel/sampled_images']\n",
    "training_images = set()\n",
    "for training_dir in training_dirs:\n",
    "    training_images.update(os.listdir(training_dir))\n",
    "\n",
    "all_img_names = [img for img in os.listdir(test_img_dir) if img.lower().endswith('.jpg') and '_top_' in img and img not in training_images]\n",
    "\n",
    "# Randomly select 300 images\n",
    "selected_img_names = random.sample(all_img_names, 300)\n",
    "\n",
    "# Create the test dataset and dataloader\n",
    "test_dataset = FilteredImagesDataset(selected_img_names, test_img_dir, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)  # Output 2 classes: Good (1) and Bad (0)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Function to test the model on the test dataset\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_img_names = []\n",
    "    all_images = []\n",
    "    with torch.no_grad():\n",
    "        for images, img_names, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_img_names.extend(img_names)\n",
    "            all_images.extend(images.cpu().numpy())\n",
    "    return all_img_names, all_preds, all_images\n",
    "\n",
    "# Load the model and move it to the appropriate device\n",
    "model = SimpleCNN()\n",
    "model_path = 'filtering_model.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Test the model and get the predictions\n",
    "img_names, preds, images = test_model(model, test_loader)\n",
    "\n",
    "# Collect corrected labels\n",
    "corrected_labels = {}\n",
    "\n",
    "current_index = 0\n",
    "out = Output()\n",
    "\n",
    "def annotate_images(index):\n",
    "    global current_index\n",
    "    current_index = index\n",
    "    img = images[index].transpose((1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "    img_name = img_names[index]\n",
    "    pred = preds[index]\n",
    "    label = \"Good\" if pred == 1 else \"Bad\"\n",
    "    \n",
    "    def on_dropdown_change(change):\n",
    "        global current_index\n",
    "        img_name = img_names[current_index]\n",
    "        corrected_label = 1 if change['new'] == \"Good\" else 0\n",
    "        corrected_labels[img_name] = corrected_label\n",
    "    \n",
    "    def on_button_click(_):\n",
    "        corrected_label = 1 if dropdown.value == \"Good\" else 0\n",
    "        corrected_labels[img_name] = corrected_label\n",
    "        next_index = min(index + 1, len(images) - 1)\n",
    "        slider.value = next_index\n",
    "    \n",
    "    dropdown = Dropdown(options=[\"Good\", \"Bad\"], value=label, description=\"Label:\")\n",
    "    dropdown.observe(on_dropdown_change, names='value')\n",
    "    \n",
    "    button = Button(description=\"Next\")\n",
    "    button.on_click(on_button_click)\n",
    "    \n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        display(HBox([Label(f\"Image: {img_name}\"), dropdown, button]))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "slider = IntSlider(min=0, max=len(images) - 1, step=1, description='Index:')\n",
    "interact(annotate_images, index=slider)\n",
    "\n",
    "display(out)\n",
    "\n",
    "# After annotation, corrected_labels will have the manually corrected labels\n",
    "print(\"Corrected Labels:\", corrected_labels)\n",
    "\n",
    "import csv\n",
    "\n",
    "# Save corrected labels to a CSV file\n",
    "with open('corrected_labels_top.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['Image', 'Corrected Label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for img_name, label in corrected_labels.items():\n",
    "        writer.writerow({'Image': img_name, 'Corrected Label': label})\n",
    "\n",
    "print(\"Corrected labels saved to corrected_labels.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the corrected labels from CSV files\n",
    "corrected_labels_top = pd.read_csv('corrected_labels_top.csv')\n",
    "corrected_labels_side = pd.read_csv('corrected_labels_side.csv')\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CorrectedImagesDataset(Dataset):\n",
    "    def __init__(self, img_names, labels, img_dir, transform=None):\n",
    "        self.img_names = img_names\n",
    "        self.labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# Define the transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "top_img_dir = '/home/ec2-user/SageMaker/notebooks/height_bright_spicy/bright_spicy_2024/top_images'\n",
    "side_img_dir = '/home/ec2-user/SageMaker/notebooks/height_bright_spicy/bright_spicy_2024/side_images'\n",
    "\n",
    "top_dataset = CorrectedImagesDataset(\n",
    "    corrected_labels_top['Image'].tolist(),\n",
    "    corrected_labels_top['Corrected Label'].tolist(),\n",
    "    top_img_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "side_dataset = CorrectedImagesDataset(\n",
    "    corrected_labels_side['Image'].tolist(),\n",
    "    corrected_labels_side['Corrected Label'].tolist(),\n",
    "    side_img_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the split ratio\n",
    "train_ratio = 0.8\n",
    "top_train_size = int(train_ratio * len(top_dataset))\n",
    "top_val_size = len(top_dataset) - top_train_size\n",
    "\n",
    "side_train_size = int(train_ratio * len(side_dataset))\n",
    "side_val_size = len(side_dataset) - side_train_size\n",
    "\n",
    "# Split the datasets\n",
    "top_train_dataset, top_val_dataset = random_split(top_dataset, [top_train_size, top_val_size])\n",
    "side_train_dataset, side_val_dataset = random_split(side_dataset, [side_train_size, side_val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(top_train_dataset + side_train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(top_val_dataset + side_val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the CNN model (reusing the previous definition)\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 16 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# Save the model after training\n",
    "torch.save(model.state_dict(), 'filtering_model2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom(growy_kernel)",
   "language": "python",
   "name": "growy_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
